{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chain_pred_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z579-ISl9Zj6"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrdZZInZP-M5",
        "outputId": "5d796735-80ba-4d69-a3a4-4160f99b7748"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT20LFmb3jSW"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import nltk\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "913VSLih4lY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "cb2bcde0-f16d-4182-e760-0b649f192ff1"
      },
      "source": [
        "data = pd.read_csv('all_train.csv')\n",
        "data.head(5)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                           QA  \\\n",
              "0           0        what movies are about [ginger rogers]   \n",
              "1           1     which movies can be described by [moore]   \n",
              "2           2  what films can be described by [occupation]   \n",
              "3           3         which films are about [jacques tati]   \n",
              "4           4         what movies are about [donnie darko]   \n",
              "\n",
              "                                            ANS           TAG  \n",
              "0  Top Hat|Kitty Foyle|The Barkleys of Broadway  has_tags_inv  \n",
              "1               Fahrenheit 9/11|Far from Heaven  has_tags_inv  \n",
              "2      Red Dawn|The Teahouse of the August Moon  has_tags_inv  \n",
              "3                     Mon Oncle|Playtime|Trafic  has_tags_inv  \n",
              "4                                      S. Darko  has_tags_inv  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d31643c-979d-4b32-8e56-9f52b276718f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>QA</th>\n",
              "      <th>ANS</th>\n",
              "      <th>TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>what movies are about [ginger rogers]</td>\n",
              "      <td>Top Hat|Kitty Foyle|The Barkleys of Broadway</td>\n",
              "      <td>has_tags_inv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>which movies can be described by [moore]</td>\n",
              "      <td>Fahrenheit 9/11|Far from Heaven</td>\n",
              "      <td>has_tags_inv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>what films can be described by [occupation]</td>\n",
              "      <td>Red Dawn|The Teahouse of the August Moon</td>\n",
              "      <td>has_tags_inv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>which films are about [jacques tati]</td>\n",
              "      <td>Mon Oncle|Playtime|Trafic</td>\n",
              "      <td>has_tags_inv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>what movies are about [donnie darko]</td>\n",
              "      <td>S. Darko</td>\n",
              "      <td>has_tags_inv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d31643c-979d-4b32-8e56-9f52b276718f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d31643c-979d-4b32-8e56-9f52b276718f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d31643c-979d-4b32-8e56-9f52b276718f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCUSf31E4m6t"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    \"\"\"\n",
        "    Normalizes latin chars with accent to their canonical decomposition\n",
        "    \"\"\"\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z0-9_?.!,¿]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFLV4RCR4pXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7e07bfb-f44a-4bc1-e153-ea013565116e"
      },
      "source": [
        "# Now we do the preprocessing using pandas and lambdas\n",
        "data[\"QA\"] = data.QA.apply(lambda w: preprocess_sentence(w))\n",
        "data[\"TAG\"] = data.TAG.apply(lambda w: preprocess_sentence(w))\n",
        "data.sample(10)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                                 QA  \\\n",
              "238265       23179  <start> the movies written by the screenwriter...   \n",
              "24748        24748  <start> when was the movie streets of blood re...   \n",
              "43527        43527  <start> who wrote the screenplay for beyond si...   \n",
              "115989       19883  <start> when were the movies starred by abbie ...   \n",
              "144873       48767  <start> who are the actors in the films writte...   \n",
              "100512        4406  <start> what were the release years of the mov...   \n",
              "279253       64167  <start> what are the genres of the movies whos...   \n",
              "259033       43947  <start> the films that share writers with the ...   \n",
              "263500       48414  <start> the films that share directors with th...   \n",
              "151048       54942  <start> who are the writers of the movies dire...   \n",
              "\n",
              "                                                      ANS  \\\n",
              "238265                                      Michael Caine   \n",
              "24748                                                2009   \n",
              "43527                                       Caroline Link   \n",
              "115989                 1968|2000|2006|2004|2009|2011|2012   \n",
              "144873  Kappei Yamaguchi|Arielle Kebbel|Minami Takayam...   \n",
              "100512                                          2014|2006   \n",
              "279253                                    Action|Thriller   \n",
              "259033                                        War|Musical   \n",
              "263500  1949|1982|1979|1978|1977|1976|1960|1946|1962|1...   \n",
              "151048                                     Diane Ruggiero   \n",
              "\n",
              "                                                      TAG  \n",
              "238265  <start> written_by written_by_inv starred_acto...  \n",
              "24748                          <start> release_year <end>  \n",
              "43527                            <start> written_by <end>  \n",
              "115989      <start> starred_actors_inv release_year <end>  \n",
              "144873        <start> written_by_inv starred_actors <end>  \n",
              "100512          <start> written_by_inv release_year <end>  \n",
              "279253  <start> directed_by directed_by_inv has_genre ...  \n",
              "259033  <start> written_by written_by_inv has_genre <end>  \n",
              "263500  <start> directed_by directed_by_inv release_ye...  \n",
              "151048           <start> directed_by_inv written_by <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6fd5f36-c982-44d6-b221-1a716611808a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>QA</th>\n",
              "      <th>ANS</th>\n",
              "      <th>TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>238265</th>\n",
              "      <td>23179</td>\n",
              "      <td>&lt;start&gt; the movies written by the screenwriter...</td>\n",
              "      <td>Michael Caine</td>\n",
              "      <td>&lt;start&gt; written_by written_by_inv starred_acto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24748</th>\n",
              "      <td>24748</td>\n",
              "      <td>&lt;start&gt; when was the movie streets of blood re...</td>\n",
              "      <td>2009</td>\n",
              "      <td>&lt;start&gt; release_year &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43527</th>\n",
              "      <td>43527</td>\n",
              "      <td>&lt;start&gt; who wrote the screenplay for beyond si...</td>\n",
              "      <td>Caroline Link</td>\n",
              "      <td>&lt;start&gt; written_by &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115989</th>\n",
              "      <td>19883</td>\n",
              "      <td>&lt;start&gt; when were the movies starred by abbie ...</td>\n",
              "      <td>1968|2000|2006|2004|2009|2011|2012</td>\n",
              "      <td>&lt;start&gt; starred_actors_inv release_year &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144873</th>\n",
              "      <td>48767</td>\n",
              "      <td>&lt;start&gt; who are the actors in the films writte...</td>\n",
              "      <td>Kappei Yamaguchi|Arielle Kebbel|Minami Takayam...</td>\n",
              "      <td>&lt;start&gt; written_by_inv starred_actors &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100512</th>\n",
              "      <td>4406</td>\n",
              "      <td>&lt;start&gt; what were the release years of the mov...</td>\n",
              "      <td>2014|2006</td>\n",
              "      <td>&lt;start&gt; written_by_inv release_year &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279253</th>\n",
              "      <td>64167</td>\n",
              "      <td>&lt;start&gt; what are the genres of the movies whos...</td>\n",
              "      <td>Action|Thriller</td>\n",
              "      <td>&lt;start&gt; directed_by directed_by_inv has_genre ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259033</th>\n",
              "      <td>43947</td>\n",
              "      <td>&lt;start&gt; the films that share writers with the ...</td>\n",
              "      <td>War|Musical</td>\n",
              "      <td>&lt;start&gt; written_by written_by_inv has_genre &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263500</th>\n",
              "      <td>48414</td>\n",
              "      <td>&lt;start&gt; the films that share directors with th...</td>\n",
              "      <td>1949|1982|1979|1978|1977|1976|1960|1946|1962|1...</td>\n",
              "      <td>&lt;start&gt; directed_by directed_by_inv release_ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151048</th>\n",
              "      <td>54942</td>\n",
              "      <td>&lt;start&gt; who are the writers of the movies dire...</td>\n",
              "      <td>Diane Ruggiero</td>\n",
              "      <td>&lt;start&gt; directed_by_inv written_by &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6fd5f36-c982-44d6-b221-1a716611808a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6fd5f36-c982-44d6-b221-1a716611808a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6fd5f36-c982-44d6-b221-1a716611808a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqM7ZncM8V9B"
      },
      "source": [
        "#### Building Vocabulary Index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rXA7-N34sok"
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word      \n",
        "\n",
        "\n",
        "inp_lang = LanguageIndex(data[\"QA\"].values.tolist())\n",
        "targ_lang = LanguageIndex(data[\"TAG\"].values.tolist())\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"QA\"].values.tolist()]\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"TAG\"].values.tolist()]\n",
        "input_tensor[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fesymsn34v7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2785ef86-0258-436c-a3c1-e28ad74dd894"
      },
      "source": [
        "target_tensor[:10]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1],\n",
              " [2, 9, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cwX-0rt4zmN"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66dJPqzV44jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5692ada-0737-40fb-e68c-0d00875af55a"
      },
      "source": [
        "\n",
        "input_tensor = pad_sequences(input_tensor, max_length_inp)\n",
        "target_tensor = pad_sequences(target_tensor, max_length_tar)\n",
        "len(target_tensor)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329282"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvatfCWS46T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb807313-a920-4657-e912-85248a5dcec4"
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor,shuffle=True, test_size=0.2)\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(263425, 263425, 65857, 65857)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNFO3obpOsoB"
      },
      "source": [
        "## Load data into DataLoader for Batching\n",
        "This is just preparing the dataset so that it can be efficiently fed into the model through batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRQKwxf479Q"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDSxA4OM5Qlp"
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2WukeVF8NVn"
      },
      "source": [
        "## Parameters\n",
        "Let's define the hyperparameters and other things we need for training our NMT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Be7lOZ5R-d"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 384\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blYXo7pv5TOu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
        "        \n",
        "    def forward(self, x, device):\n",
        "        #x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) \n",
        "        return output, self.hidden\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4djvgil5bMQ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.V = nn.Linear(self.enc_units, 1)\n",
        "    \n",
        "    def forward(self, x, hidden, enc_output):\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        x = self.embedding(x)\n",
        "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
        "        output, state = self.gru(x)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((1, self.batch_sz, self.dec_units))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QclyWIop5dRG"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "def loss_function(real, pred):\n",
        "    mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
        "    loss_ = criterion(pred, real) * mask \n",
        "    return torch.mean(loss_)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjMMYJv85hVT"
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpQU6MhEUfFL"
      },
      "source": [
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]    \n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8G-3YY8ADm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164a43e2-24d0-4502-96a9-f014b0044041"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "EPOCHS = 1\n",
        "def eval2(encoder, decoder, sentence, max_length=120):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    sentence = torch.unsqueeze(sentence, dim=1)\n",
        "    with torch.no_grad():\n",
        "        print(sentence.size())\n",
        "        \n",
        "        x_batch = xs.detach().numpy()\n",
        "        emb_output = torch.tensor(np.array([sbert.encode([inp_lang.idx2word[w] for w in sentence]) for sentence in x_batch]))\n",
        "        enc_output, enc_hidden = encoder(emb_output.to(device), device)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * 1)\n",
        "        out_sentence = []\n",
        "        for t in range(1, sentence.size(0)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                        dec_hidden.to(device), \n",
        "                                        enc_output.to(device))\n",
        "            dec_input = predictions.argmax(dim=1).unsqueeze(1)\n",
        "            # print(dec_input)\n",
        "            out_sentence.append(targ_lang.idx2word[predictions.squeeze().argmax().item()])\n",
        "            # print(out_sentence)\n",
        "            \n",
        "            # print(predictions.size())\n",
        "    return out_sentence\n",
        "\n",
        "\n",
        "encoder.batch_sz = 64\n",
        "encoder.initialize_hidden_state(device)\n",
        "decoder.batch_sz = 64\n",
        "decoder.initialize_hidden_state()\n",
        "\n",
        "for epoch in range(EPOCHS):    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "        enc_output, enc_hidden = encoder(xs.to(device), device)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "        for t in range(1, ys.size(1)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "            \n",
        "            loss += loss_function(ys[:, t].long().to(device), predictions.to(device))\n",
        "            dec_input = ys[:, t].unsqueeze(1)\n",
        "\n",
        "        batch_loss = (loss / int(ys.size(1)))\n",
        "        total_loss += batch_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.detach().item()))\n",
        "       \n",
        "        \n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1681\n",
            "Epoch 1 Batch 100 Loss 0.1155\n",
            "Epoch 1 Batch 200 Loss 0.1732\n",
            "Epoch 1 Batch 300 Loss 0.1213\n",
            "Epoch 1 Batch 400 Loss 0.1206\n",
            "Epoch 1 Batch 500 Loss 0.1578\n",
            "Epoch 1 Batch 600 Loss 0.1276\n",
            "Epoch 1 Batch 700 Loss 0.1146\n",
            "Epoch 1 Batch 800 Loss 0.1574\n",
            "Epoch 1 Batch 900 Loss 0.1414\n",
            "Epoch 1 Batch 1000 Loss 0.1210\n",
            "Epoch 1 Batch 1100 Loss 0.1469\n",
            "Epoch 1 Batch 1200 Loss 0.1476\n",
            "Epoch 1 Batch 1300 Loss 0.1565\n",
            "Epoch 1 Batch 1400 Loss 0.0604\n",
            "Epoch 1 Batch 1500 Loss 0.0472\n",
            "Epoch 1 Batch 1600 Loss 0.0346\n",
            "Epoch 1 Batch 1700 Loss 0.0442\n",
            "Epoch 1 Batch 1800 Loss 0.0122\n",
            "Epoch 1 Batch 1900 Loss 0.0005\n",
            "Epoch 1 Batch 2000 Loss 0.0003\n",
            "Epoch 1 Batch 2100 Loss 0.0002\n",
            "Epoch 1 Batch 2200 Loss 0.0001\n",
            "Epoch 1 Batch 2300 Loss 0.0001\n",
            "Epoch 1 Batch 2400 Loss 0.0024\n",
            "Epoch 1 Batch 2500 Loss 0.0001\n",
            "Epoch 1 Batch 2600 Loss 0.0001\n",
            "Epoch 1 Batch 2700 Loss 0.0002\n",
            "Epoch 1 Batch 2800 Loss 0.0063\n",
            "Epoch 1 Batch 2900 Loss 0.0088\n",
            "Epoch 1 Batch 3000 Loss 0.0001\n",
            "Epoch 1 Batch 3100 Loss 0.0000\n",
            "Epoch 1 Batch 3200 Loss 0.0000\n",
            "Epoch 1 Batch 3300 Loss 0.0000\n",
            "Epoch 1 Batch 3400 Loss 0.0000\n",
            "Epoch 1 Batch 3500 Loss 0.0000\n",
            "Epoch 1 Batch 3600 Loss 0.0000\n",
            "Epoch 1 Batch 3700 Loss 0.0001\n",
            "Epoch 1 Batch 3800 Loss 0.0001\n",
            "Epoch 1 Batch 3900 Loss 0.0001\n",
            "Epoch 1 Batch 4000 Loss 0.0005\n",
            "Epoch 1 Batch 4100 Loss 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYBffn-2Hao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abba0271-08a9-4cfa-e331-a2bf8d529ae7"
      },
      "source": [
        "def translate_sentence(encoder, decoder, sentence, max_length=120):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    total_loss = 0\n",
        "    sentence = sentence.transpose(0, 1)\n",
        "    with torch.no_grad():\n",
        "        enc_output, enc_hidden = encoder(sentence.to(device), device)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * 1)\n",
        "        out_sentence = []\n",
        "        for t in range(1, sentence.size(0)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
        "                                                 dec_hidden.to(device),\n",
        "                                                 enc_output.to(device))\n",
        "            dec_input = predictions.argmax(dim=1).unsqueeze(1)\n",
        "            next_word = targ_lang.idx2word[predictions.squeeze().argmax().item()]\n",
        "            out_sentence.append(next_word)\n",
        "            if next_word == '<end>':\n",
        "                break\n",
        "    return out_sentence\n",
        "\n",
        "\n",
        "encoder.batch_sz = 1\n",
        "encoder.initialize_hidden_state(device)\n",
        "decoder.batch_sz = 1\n",
        "decoder.initialize_hidden_state()\n",
        "\n",
        "test_sentence = \"<start> which films have the same screenwriter of a tree grows in brooklyn <end>\"\n",
        "test_sentence = [[inp_lang.word2idx[s] for s in test_sentence.split(' ')]]\n",
        "test_sentence = pad_sequences(test_sentence, max_length_inp)\n",
        "ret = translate_sentence(encoder, decoder, torch.tensor(test_sentence), max_length=max_length_tar)\n",
        "ret"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start>', 'written_by', 'written_by_inv', '<end>']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def predict_sentences(sentences):\n",
        "    def predict_sentence(test_sentence):\n",
        "        test_sentence = preprocess_sentence(test_sentence)\n",
        "        test_sentence = [[inp_lang.word2idx[s] for s in test_sentence.split(' ') if s in inp_lang.word2idx]]\n",
        "        test_sentence = pad_sequences(test_sentence, max_length_inp)\n",
        "        return translate_sentence(encoder, decoder, torch.tensor(test_sentence), max_length=max_length_tar)\n",
        "\n",
        "    return [predict_sentence(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "NV5yiIj7jOp7"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_test = pd.read_csv('all_test.csv').dropna().iloc[:2000]\n",
        "tags_pred = predict_sentences(data_test['QA'].values)\n",
        "tags_true = [preprocess_sentence(sentence).split(' ') for sentence in data_test['TAG']]\n",
        "\n",
        "tags_original = tags_pred.copy()\n",
        "true_tags_original = tags_true.copy()\n",
        "def clean_tags(tags):\n",
        "    while len(tags) > 0 and tags[0].startswith(\"<\"):\n",
        "        tags.pop(0)\n",
        "    if '<end>' in tags:\n",
        "        return tags[:tags.index('<end>')]\n",
        "    return [tag for tag in tags if not tag.startswith(\"<\")]\n",
        "new_tags_pred = [clean_tags(tags) for tags in tags_original]\n",
        "new_tags_true = [clean_tags(tags) for tags in true_tags_original]\n",
        "\n",
        "tags_true_processed = np.array([' '.join(words) for words in new_tags_pred])\n",
        "tags_pred_processed = np.array([' '.join(words) for words in new_tags_true])\n",
        "print(tags_pred_processed.shape, tags_true_processed.shape)\n",
        "\n",
        "results = pd.DataFrame(np.array([data_test.QA.values,tags_true_processed,tags_pred_processed]).transpose(),\n",
        "                       columns=['QA','Original','Predicted'])\n",
        "results.to_csv('results_sbert.csv')"
      ],
      "metadata": {
        "id": "GZTCTiC0hFfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3603c3fe-3118-4168-a503-d17f85549d3c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000,) (2000,)\n"
          ]
        }
      ]
    }
  ]
}